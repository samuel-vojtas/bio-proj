{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import insightface\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "with open(\"config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "batch_size = config['training']['batch_size']\n",
    "learning_rate = config['training']['learning_rate']\n",
    "patience = config['training']['patience']\n",
    "min_delta = config['training']['min_delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8\n",
      "Testing samples: 2\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/'\n",
    "train_ratio = 0.8\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/huginn/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/huginn/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/huginn/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/huginn/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/huginn/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "model = insightface.app.FaceAnalysis(name=\"buffalo_l\", providers=['CPUExecutionProvider'])\n",
    "model.prepare(ctx_id=-1)  # ctx_id=-1 forces CPU mode\n",
    "\n",
    "class ArcFaceFineTune(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(ArcFaceFineTune, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# Initialize the fine-tuning model with the ArcFace feature extractor\n",
    "fine_tune_model = ArcFaceFineTune(model).to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings(model, img_tensor):\n",
    "    img_pil = transforms.ToPILImage()(img_tensor).convert(\"RGB\")\n",
    "    img_np = np.array(img_pil)\n",
    "\n",
    "    # Run face detection and extract embeddings\n",
    "    faces = model.get(img_np)\n",
    "    \n",
    "    # Check if any faces were detected\n",
    "    if len(faces) > 0:\n",
    "        return faces[0].normed_embedding\n",
    "    else:\n",
    "        print(\"No face detected in the image.\")\n",
    "        return None\n",
    "\n",
    "# Example usage: extracting embeddings for the first image in the dataset\n",
    "sample_image, _ = train_dataset[0]\n",
    "sample_embedding = extract_embeddings(model, sample_image)  # Convert to NumPy array\n",
    "print(f\"Embedding shape: {sample_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7007\n",
      "Epoch [2/10], Loss: 0.7001\n",
      "Early stopping at epoch 2\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Use cross-entropy loss for classification\n",
    "optimizer = optim.Adam(fine_tune_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    fine_tune_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        embeddings = []\n",
    "        for img_tensor in inputs:\n",
    "            embedding = extract_embeddings(model, img_tensor)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "        if len(embeddings) > 0:\n",
    "            embeddings_tensor = torch.stack([torch.tensor(e) for e in embeddings])\n",
    "            labels = labels[:len(embeddings)]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = fine_tune_model(embeddings_tensor)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping based on min_delta (if loss improvement is too small)\n",
    "    if epoch > 0 and abs(train_losses[-1] - train_losses[-2]) < min_delta:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        embeddings = []\n",
    "        \n",
    "        for img_tensor in inputs:\n",
    "            embedding = extract_embeddings(model, img_tensor)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "        \n",
    "        if len(embeddings) > 0:\n",
    "            embeddings_tensor = torch.stack([torch.tensor(e) for e in embeddings])\n",
    "            labels = labels[:len(embeddings)]\n",
    "            \n",
    "            outputs = fine_tune_model(embeddings_tensor)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += len(predicted)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(fine_tune_model.state_dict(), './results/fine_tuned_arcface.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
